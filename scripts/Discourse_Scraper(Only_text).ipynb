{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THXUr5wSj7oC",
        "outputId": "d9e6af6f-9d95-4c10-9628-8840bf7b19da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verifying authentication...\n",
            "Authentication successful.\n",
            "Fetching topics from category 'courses/tds-kb/34'...\n",
            "Fetched 30 topics from page 0. Total: 30\n",
            "Fetched 30 topics from page 1. Total: 60\n",
            "Fetched 30 topics from page 2. Total: 90\n",
            "Fetched 30 topics from page 3. Total: 120\n",
            "Fetched 30 topics from page 4. Total: 150\n",
            "Fetched 30 topics from page 5. Total: 180\n",
            "Fetched 30 topics from page 6. Total: 210\n",
            "Fetched 30 topics from page 7. Total: 240\n",
            "Fetched 30 topics from page 8. Total: 270\n",
            "Fetched 30 topics from page 9. Total: 300\n",
            "Fetched 30 topics from page 10. Total: 330\n",
            "Fetched 30 topics from page 11. Total: 360\n",
            "Fetched 30 topics from page 12. Total: 390\n",
            "Fetched 30 topics from page 13. Total: 420\n",
            "Fetched 30 topics from page 14. Total: 450\n",
            "\n",
            "Fetched 450 total topics.\n",
            "Collecting posts from topics, processing images to base64, and running OCR...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:   4%|▎         | 16/450 [00:55<30:33,  4.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 50 posts\n",
            "[Skip OCR] Too small: 1344 bytes\n",
            "[💾] Backup saved with 100 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:   4%|▎         | 16/450 [00:58<30:33,  4.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 895 bytes\n",
            "  [Skipped] Tiny image (690x12) in post 590891\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:   4%|▎         | 16/450 [00:59<30:33,  4.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Skipped] Tiny image (690x22) in post 590974\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:   5%|▌         | 23/450 [01:14<18:27,  2.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 150 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  11%|█         | 50/450 [01:57<08:59,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 699 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  11%|█         | 50/450 [01:58<08:59,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1437 bytes\n",
            "[💾] Backup saved with 200 posts\n",
            "[💾] Backup saved with 250 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [02:11<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 300 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [02:41<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1604 bytes\n",
            "[💾] Backup saved with 350 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [02:43<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1314 bytes\n",
            "[Skip OCR] Too small: 1318 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [02:43<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1045 bytes\n",
            "[Skip OCR] Too small: 1052 bytes\n",
            "[💾] Backup saved with 400 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [02:46<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 886 bytes\n",
            "[💾] Backup saved with 450 posts\n",
            "[💾] Backup saved with 500 posts\n",
            "[💾] Backup saved with 550 posts\n",
            "[💾] Backup saved with 600 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [02:53<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1407 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [02:53<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1387 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [02:54<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1387 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [02:54<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1849 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [02:54<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1024 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [02:55<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1489 bytes\n",
            "[💾] Backup saved with 650 posts\n",
            "[💾] Backup saved with 700 posts\n",
            "[💾] Backup saved with 750 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [03:00<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [03:00<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 886 bytes\n",
            "[Skip OCR] Too small: 886 bytes\n",
            "[Skip OCR] Too small: 886 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [03:01<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1941 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [03:01<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1941 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [03:02<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Image Error] for post 619143: 'NoneType' object has no attribute 'seek'\n",
            "[Skip OCR] Too small: 1941 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  12%|█▏        | 56/450 [03:02<13:44,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 886 bytes\n",
            "[Skip OCR] Too small: 886 bytes\n",
            "[Skip OCR] Too small: 886 bytes\n",
            "[💾] Backup saved with 800 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  15%|█▌        | 68/450 [03:39<10:38,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1449 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  15%|█▌        | 68/450 [03:39<10:38,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1449 bytes\n",
            "[💾] Backup saved with 850 posts\n",
            "[💾] Backup saved with 900 posts\n",
            "[💾] Backup saved with 950 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  15%|█▌        | 68/450 [03:46<10:38,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1387 bytes\n",
            "[💾] Backup saved with 1000 posts\n",
            "[💾] Backup saved with 1050 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  15%|█▌        | 68/450 [03:50<10:38,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Image Error] for post 615124: 'NoneType' object has no attribute 'seek'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  15%|█▌        | 68/450 [03:52<10:38,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Image Error] for post 615988: 'NoneType' object has no attribute 'seek'\n",
            "[💾] Backup saved with 1100 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  15%|█▌        | 68/450 [03:53<10:38,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 967 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  15%|█▌        | 68/450 [03:54<10:38,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 941 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  15%|█▌        | 68/450 [03:55<10:38,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1675 bytes\n",
            "[💾] Backup saved with 1150 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  15%|█▌        | 68/450 [04:00<10:38,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Image Error] for post 616584: 'NoneType' object has no attribute 'seek'\n",
            "[💾] Backup saved with 1200 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  15%|█▌        | 68/450 [04:01<10:38,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1449 bytes\n",
            "[Skip OCR] Too small: 1387 bytes\n",
            "[💾] Backup saved with 1250 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  16%|█▌        | 72/450 [04:09<37:56,  6.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 1300 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  18%|█▊        | 79/450 [04:21<10:59,  1.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1924 bytes\n",
            "  [Skipped] Tiny image (16x16) in post 618184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  18%|█▊        | 83/450 [04:26<09:18,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 1350 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  19%|█▉        | 86/450 [04:34<12:23,  2.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 1400 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  20%|█▉        | 88/450 [04:40<11:05,  1.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1304 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3570: UserWarning: image file could not be identified because AVIF support not installed\n",
            "  warnings.warn(message)\n",
            "Processing topics:  20%|█▉        | 88/450 [04:40<11:05,  1.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Image Error] Skipped: not a valid image for post 617454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  20%|██        | 92/450 [04:46<10:01,  1.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Image Error] for post 614549: 'NoneType' object has no attribute 'seek'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rProcessing topics:  21%|██        | 93/450 [04:47<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 1450 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:13<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Image Error] for post 587355: 'NoneType' object has no attribute 'seek'\n",
            "[💾] Backup saved with 1500 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:15<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1674 bytes\n",
            "[Skip OCR] Too small: 1449 bytes\n",
            "[Skip OCR] Too small: 1449 bytes\n",
            "[Skip OCR] Too small: 1983 bytes\n",
            "[Skip OCR] Too small: 1983 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:15<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1983 bytes\n",
            "[💾] Backup saved with 1550 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:16<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1387 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[💾] Backup saved with 1600 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:18<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Image Error] for post 594359: 'NoneType' object has no attribute 'seek'\n",
            "[Skip OCR] Too small: 1449 bytes\n",
            "[Skip OCR] Too small: 1449 bytes\n",
            "[💾] Backup saved with 1650 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:20<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Skipped] Tiny image (16x16) in post 594846\n",
            "[💾] Backup saved with 1700 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:20<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1674 bytes\n",
            "[Skip OCR] Too small: 1449 bytes\n",
            "[Skip OCR] Too small: 1449 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:21<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1695 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:21<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1690 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:21<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1695 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1690 bytes\n",
            "[Skip OCR] Too small: 1695 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1690 bytes\n",
            "[Skip OCR] Too small: 1695 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1690 bytes\n",
            "[Skip OCR] Too small: 1695 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1690 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1695 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1690 bytes\n",
            "[Skip OCR] Too small: 1695 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1690 bytes\n",
            "[Skip OCR] Too small: 1695 bytes\n",
            "[Skip OCR] Too small: 1674 bytes\n",
            "[Skip OCR] Too small: 1449 bytes\n",
            "[Skip OCR] Too small: 1449 bytes\n",
            "[Skip OCR] Too small: 1387 bytes\n",
            "[Skip OCR] Too small: 1690 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:22<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1695 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[Skip OCR] Too small: 1690 bytes\n",
            "[Skip OCR] Too small: 1695 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n",
            "[💾] Backup saved with 1750 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:26<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1449 bytes\n",
            "[Skip OCR] Too small: 1449 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:26<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 1800 posts\n",
            "[Skip OCR] Too small: 1674 bytes\n",
            "[Skip OCR] Too small: 1387 bytes\n",
            "[Skip OCR] Too small: 1690 bytes\n",
            "[Skip OCR] Too small: 1674 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:27<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1387 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:27<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1690 bytes\n",
            "[Skip OCR] Too small: 1674 bytes\n",
            "[Skip OCR] Too small: 1387 bytes\n",
            "[💾] Backup saved with 1850 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:29<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1674 bytes\n",
            "[Skip OCR] Too small: 1387 bytes\n",
            "[Skip OCR] Too small: 1469 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:30<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 1900 posts\n",
            "[Skip OCR] Too small: 1449 bytes\n",
            "[Skip OCR] Too small: 1449 bytes\n",
            "[Skip OCR] Too small: 1387 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:30<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1674 bytes\n",
            "[💾] Backup saved with 1950 posts\n",
            "[💾] Backup saved with 2000 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  21%|██        | 93/450 [05:32<09:43,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Skipped] Tiny image (677x28) in post 596606\n",
            "  [Image Error] for post 596606: 'NoneType' object has no attribute 'seek'\n",
            "[💾] Backup saved with 2050 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  22%|██▏       | 101/450 [05:47<15:13,  2.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 2100 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  23%|██▎       | 102/450 [05:50<14:05,  2.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1808 bytes\n",
            "[Skip OCR] Too small: 1941 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  23%|██▎       | 102/450 [05:50<14:05,  2.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 861 bytes\n",
            "[Skip OCR] Too small: 1941 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  23%|██▎       | 102/450 [05:51<14:05,  2.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1246 bytes\n",
            "[Skip OCR] Too small: 1808 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  23%|██▎       | 102/450 [05:51<14:05,  2.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1366 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  24%|██▍       | 107/450 [05:59<09:54,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Image Error] for post 604239: 'NoneType' object has no attribute 'seek'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rProcessing topics:  24%|██▍       | 108/450 [06:01<11:59,  2.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 2150 posts\n",
            "[💾] Backup saved with 2200 posts\n",
            "[💾] Backup saved with 2250 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  25%|██▌       | 113/450 [06:16<11:34,  2.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 2300 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  25%|██▌       | 113/450 [06:22<11:34,  2.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 565 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  25%|██▌       | 113/450 [06:22<11:34,  2.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1675 bytes\n",
            "[💾] Backup saved with 2350 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  26%|██▌       | 116/450 [06:30<14:36,  2.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1388 bytes\n",
            "[💾] Backup saved with 2400 posts\n",
            "[💾] Backup saved with 2450 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  26%|██▌       | 117/450 [06:34<19:58,  3.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1387 bytes\n",
            "[Skip OCR] Too small: 1437 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  27%|██▋       | 120/450 [06:38<12:20,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 1675 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  28%|██▊       | 124/450 [06:44<09:02,  1.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Skip OCR] Too small: 535 bytes\n",
            "[Skip OCR] Too small: 535 bytes\n",
            "[Skip OCR] Too small: 535 bytes\n",
            "[Skip OCR] Too small: 535 bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rProcessing topics:  28%|██▊       | 125/450 [06:46<09:39,  1.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 2500 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  30%|██▉       | 133/450 [06:57<07:33,  1.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 2550 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  30%|███       | 135/450 [07:01<08:04,  1.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 2600 posts\n",
            "[💾] Backup saved with 2650 posts\n",
            "[💾] Backup saved with 2700 posts\n",
            "[💾] Backup saved with 2750 posts\n",
            "[💾] Backup saved with 2800 posts\n",
            "[💾] Backup saved with 2850 posts\n",
            "[💾] Backup saved with 2900 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  31%|███       | 140/450 [07:41<18:06,  3.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 2950 posts\n",
            "  [Skipped] Tiny image (16x16) in post 595921\n",
            "[💾] Backup saved with 3000 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  33%|███▎      | 147/450 [07:53<09:06,  1.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 3050 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  34%|███▍      | 155/450 [08:06<06:57,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 3100 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  35%|███▌      | 159/450 [08:13<07:07,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 3150 posts\n",
            "[💾] Backup saved with 3200 posts\n",
            "[💾] Backup saved with 3250 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  37%|███▋      | 165/450 [08:41<11:11,  2.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 3300 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics:  40%|███▉      | 178/450 [09:00<06:01,  1.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[💾] Backup saved with 3350 posts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing topics: 100%|██████████| 450/450 [15:49<00:00,  2.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collected 3380 posts.\n",
            "Scraping complete. Saved 3380 posts to tds_discourse_data.json\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import io\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import base64\n",
        "import google.generativeai as genai\n",
        "from PIL import UnidentifiedImageError\n",
        "import random\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "def create_session_with_browser_cookies(discourse_url, cookies):\n",
        "    \"\"\"Creates a requests session with the provided cookies.\"\"\"\n",
        "    session = requests.Session()\n",
        "    # Check if cookies are present before setting them\n",
        "    if not all(cookies.values()):\n",
        "        print(\"Error: One or more cookie environment variables are not set.\")\n",
        "        print(\"Please check your .env file.\")\n",
        "        exit()\n",
        "\n",
        "    for name, value in cookies.items():\n",
        "        session.cookies.set(name, value, domain=discourse_url.split('//')[1])\n",
        "    return session\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "\n",
        "def fetch_all_posts_from_topic(topic_id):\n",
        "    \"\"\"\n",
        "    Fetch all posts from a Discourse topic using post_stream.stream post IDs.\n",
        "    Returns the full list of post data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Step 1: Get initial topic JSON with metadata and some posts\n",
        "        url = f\"{DISCOURSE_URL}/t/{topic_id}.json\"\n",
        "        response = session.get(url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        topic_json = response.json()\n",
        "\n",
        "        all_post_ids = topic_json.get(\"post_stream\", {}).get(\"stream\", [])\n",
        "        fetched_posts = topic_json.get(\"post_stream\", {}).get(\"posts\", [])\n",
        "        fetched_post_ids = {p['id'] for p in fetched_posts}\n",
        "\n",
        "        remaining_ids = [pid for pid in all_post_ids if pid not in fetched_post_ids]\n",
        "        all_posts = list(fetched_posts)\n",
        "\n",
        "        # Step 2: Paginate through the remaining post IDs in chunks\n",
        "        chunk_size = 20\n",
        "        for i in range(0, len(remaining_ids), chunk_size):\n",
        "            chunk = remaining_ids[i:i + chunk_size]\n",
        "            chunk_url = f\"{DISCOURSE_URL}/t/{topic_id}/posts.json\"\n",
        "            params = {'post_ids[]': chunk}\n",
        "            chunk_resp = session.get(chunk_url, params=params, timeout=30)\n",
        "            chunk_resp.raise_for_status()\n",
        "            chunk_data = chunk_resp.json()\n",
        "            all_posts.extend(chunk_data.get('post_stream', {}).get('posts', []))\n",
        "\n",
        "            time.sleep(0.5)  # Respectful delay\n",
        "\n",
        "        return all_posts\n",
        "\n",
        "    except Exception as e:\n",
        "        tqdm.write(f\"Error fetching posts from topic {topic_id}: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def get_text_from_image_data(image_data, max_retries=10):\n",
        "    \"\"\"Uses Gemini API to extract embedded text from image data with retry on failure.\"\"\"\n",
        "    if os.getenv(\"ENABLE_OCR\", \"1\") != \"1\":\n",
        "        return \"\"\n",
        "\n",
        "    attempt = 0\n",
        "    while attempt < max_retries:\n",
        "        try:\n",
        "            model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "            # Validate and re-open image\n",
        "            img = Image.open(io.BytesIO(image_data))\n",
        "            img.verify()\n",
        "            img = Image.open(io.BytesIO(image_data))\n",
        "            if len(image_data) < 2000:\n",
        "\n",
        "                print(\"[Skip] Image too small, likely emoji or icon\")\n",
        "                return \"\"\n",
        "            # Convert to PNG bytes\n",
        "                if (\n",
        "                  'avatar' in img_url or\n",
        "                  img_url.endswith('.svg') or\n",
        "                  'emoji' in img_url or\n",
        "                  'emoji' in img_tag.get('class', []) or\n",
        "                  '/images/emoji' in img_url):\n",
        "                  tqdm.write(f\"  [Skipped] Emoji/system image: {img_url}\")\n",
        "                  continue\n",
        "\n",
        "            buffered = io.BytesIO()\n",
        "            img.save(buffered, format=\"PNG\")\n",
        "            image_bytes = buffered.getvalue()\n",
        "\n",
        "            # Call Gemini API\n",
        "            response = model.generate_content(\n",
        "                [\n",
        "                    {\n",
        "                        \"mime_type\": \"image/png\",\n",
        "                        \"data\": image_bytes\n",
        "                    },\n",
        "                    \"\"\" You are an OCR and image-context assistant. Return exactly two sentences and nothing else.\n",
        "1. First sentence: verbatim extract of all text in the image.\n",
        "2. Second sentence: a concise explanation of the image’s context.\n",
        "Do not include headings, labels, bullet points, or extra commentary.\"\"\"\n",
        "                ]\n",
        "            )\n",
        "            print(response.text.strip())\n",
        "            time.sleep(5)  # Rate limit spacing\n",
        "            return response.text.strip()\n",
        "\n",
        "        except UnidentifiedImageError:\n",
        "            print(f\"[Gemini OCR Error] Skipped invalid image (not recognized format)\")\n",
        "            return \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            attempt += 1\n",
        "            if \"429\" in str(e) or \"Rate limit\" in str(e):\n",
        "                wait_time = 90 + random.uniform(0, 15)\n",
        "                print(f\"[Rate Limit] Attempt {attempt}/{max_retries} — Waiting {wait_time:.1f}s before retrying...\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                print(f\"[Gemini OCR Error] Attempt {attempt}/{max_retries} — Error: {e}\")\n",
        "                time.sleep(5)  # Brief wait for transient errors\n",
        "\n",
        "    print(\"[Gemini OCR Error] Max retries exceeded. OCR failed.\")\n",
        "    return \"\"\n",
        "\n",
        "# --- SETUP ---\n",
        "OUTPUT_FILE = \"tds_discourse_data.json\"\n",
        "DISCOURSE_URL = \"https://discourse.onlinedegree.iitm.ac.in\"\n",
        "COURSE_CATEGORY_SLUG = \"courses/tds-kb/34\" # Specific slug for \"Tools in Data Science\"\n",
        "DISCOURSE_COOKIE_T=os.getenv(\"DISCOURSE_COOKIE_T\")\n",
        "DISCOURSE_COOKIE_SESSION=os.getenv(\"DISCOURSE_COOKIE_SESSION\")\n",
        "# --- REVISED: Fetch cookies securely from environment variables ---\n",
        "browser_cookies = {\n",
        "    '_t': DISCOURSE_COOKIE_T,\n",
        "    '_forum_session': DISCOURSE_COOKIE_SESSION\n",
        "}\n",
        "\n",
        "session = create_session_with_browser_cookies(DISCOURSE_URL, browser_cookies)\n",
        "\n",
        "# Verify login by checking the current session\n",
        "print(\"Verifying authentication...\")\n",
        "response = session.get(f\"{DISCOURSE_URL}/session/current.json\", timeout=20)\n",
        "if response.status_code != 200 or \"current_user\" not in response.json():\n",
        "    print(\"Authentication failed. Please check your cookies in the .env file.\")\n",
        "    exit()\n",
        "print(\"Authentication successful.\")\n",
        "\n",
        "\n",
        "# Define time range for posts\n",
        "start_date = datetime(2025, 1, 1)\n",
        "end_date = datetime(2025, 4, 15)\n",
        "\n",
        "# Get topics from the specified category\n",
        "topics = []\n",
        "page = 0\n",
        "print(f\"Fetching topics from category '{COURSE_CATEGORY_SLUG}'...\")\n",
        "for i in range(15):\n",
        "    url = f\"{DISCOURSE_URL}/c/{COURSE_CATEGORY_SLUG}.json?page={page}\"\n",
        "    try:\n",
        "        resp = session.get(url, timeout=30)\n",
        "        resp.raise_for_status()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to fetch topics on page {page}: {e}\")\n",
        "        break\n",
        "\n",
        "    data = resp.json()\n",
        "    page_topics = data.get('topic_list', {}).get('topics', [])\n",
        "    if not page_topics:\n",
        "        print(\"No more topics found.\")\n",
        "        break\n",
        "\n",
        "    topics.extend(page_topics)\n",
        "    print(f\"Fetched {len(page_topics)} topics from page {page}. Total: {len(topics)}\")\n",
        "    page += 1\n",
        "    time.sleep(1) # Be polite to the server\n",
        "\n",
        "print(f\"\\nFetched {len(topics)} total topics.\")\n",
        "\n",
        "# Fetch and process posts within the date range\n",
        "all_posts = []\n",
        "print(\"Collecting posts from topics, processing images to base64, and running OCR...\")\n",
        "BACKUP_INTERVAL = 50\n",
        "for topic in tqdm(topics, desc=\"Processing topics\"):\n",
        "    topic_id = topic['id']\n",
        "    posts = fetch_all_posts_from_topic(topic_id)\n",
        "\n",
        "    for post in posts:\n",
        "        try:\n",
        "          created_at = datetime.strptime(post['created_at'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
        "        except (ValueError, TypeError):\n",
        "            continue # Skip post if date format is wrong or missing\n",
        "\n",
        "        if start_date <= created_at < end_date:\n",
        "            post_content_html = post.get(\"cooked\", \"\")\n",
        "            soup = BeautifulSoup(post_content_html, 'html.parser')\n",
        "\n",
        "            images_base64 = []\n",
        "            extracted_image_text = \"\"\n",
        "\n",
        "            for img_tag in soup.find_all('img'):\n",
        "                img_url = img_tag.get('src')\n",
        "                if not img_url:\n",
        "                    continue\n",
        "                if 'avatar' in img_url or img_url.endswith('.svg'):\n",
        "                    continue\n",
        "                if img_url.startswith('/'):\n",
        "                    img_url = DISCOURSE_URL + img_url\n",
        "\n",
        "                try:\n",
        "                    img_response = session.get(img_url, timeout=20)\n",
        "                    img_response.raise_for_status()\n",
        "                    image_data = img_response.content\n",
        "\n",
        "                    # Validate image before converting to base64 or OCR\n",
        "                    img = Image.open(io.BytesIO(image_data))\n",
        "                    img.verify()\n",
        "\n",
        "\n",
        "\n",
        "                    # Skip images that are too small (likely emojis or icons)\n",
        "                    if img.width < 32 or img.height < 32:\n",
        "                        tqdm.write(f\"  [Skipped] Tiny image ({img.width}x{img.height}) in post {post.get('id')}\")\n",
        "                        continue\n",
        "\n",
        "\n",
        "\n",
        "                    # Optionally: Skip nearly grayscale or low-info images\n",
        "                    if img.getbands() == ('L',) and len(set(img.getdata())) < 10:\n",
        "                        tqdm.write(f\"  [Skipped] Low-info grayscale image in post {post.get('id')}\")\n",
        "                        continue\n",
        "\n",
        "                    img = Image.open(io.BytesIO(image_data))  # Reopen after verify\n",
        "\n",
        "                    # Encode to base64\n",
        "                    base64_bytes = base64.b64encode(image_data)\n",
        "                    base64_string = base64_bytes.decode('utf-8')\n",
        "                    images_base64.append(base64_string)\n",
        "\n",
        "                    # OCR\n",
        "                    # ocr_text = get_text_from_image_data(image_data)\n",
        "                    if len(image_data) < 2000:\n",
        "                        tqdm.write(f\"[Skip OCR] Too small: {len(image_data)} bytes\")\n",
        "                        continue\n",
        "\n",
        "                    # if ocr_text:\n",
        "                    #     extracted_image_text += ocr_text + \"\\n---\\n\"\n",
        "\n",
        "                except UnidentifiedImageError:\n",
        "                    tqdm.write(f\"  [Image Error] Skipped: not a valid image for post {post.get('id')}\")\n",
        "                except Exception as img_e:\n",
        "                    tqdm.write(f\"  [Image Error] for post {post.get('id')}: {img_e}\")\n",
        "\n",
        "            all_posts.append({\n",
        "                \"source\": \"discourse\",\n",
        "                \"id\": f\"discourse_{post.get('id')}\",\n",
        "                \"title\": topic.get(\"title\", \"Untitled Topic\"),\n",
        "                \"content_text\": soup.get_text(separator=\"\\n\", strip=True),\n",
        "                \"images_base64\": images_base64, # <-- SAVING THE LIST OF BASE64 STRINGS\n",
        "                \"extracted_image_text\": extracted_image_text.strip(),\n",
        "                \"url\": f\"{DISCOURSE_URL}/t/{topic_id}/{post.get('post_number', 1)}\",\n",
        "                \"metadata\": {\n",
        "                    \"username\": post.get(\"username\", \"unknown\"),\n",
        "                    \"created_at\": created_at.isoformat(),\n",
        "                    \"topic_id\": topic_id,\n",
        "                    \"post_number\": post.get(\"post_number\", 0)\n",
        "                }\n",
        "            })\n",
        "            if len(all_posts) % BACKUP_INTERVAL == 0:\n",
        "              with open(\"backup.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "                  json.dump(all_posts, f, indent=2, ensure_ascii=False)\n",
        "              print(f\"[💾] Backup saved with {len(all_posts)} posts\")\n",
        "    time.sleep(1)\n",
        "\n",
        "print(f\"\\nCollected {len(all_posts)} posts.\")\n",
        "\n",
        "# Save the unified data to a file\n",
        "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(all_posts, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"Scraping complete. Saved {len(all_posts)} posts to {OUTPUT_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_t9LV2GkA1r"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
